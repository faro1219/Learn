\chapter{Stability} 
It would be a fine thing if numerical algorithms could provide exact solutions to numerical problems. Since the problems are continuous while digital computers are discrete, however, this is generally not possible. The notion of stability is the standard way of characterizing what is possible-numerical analysts' idea of what it means to get the "right answer," even if it is not exact.

\section{Algorithms} 
Recall \autoref{def: Problem}, we can define algorithms. 

%────────────────────────────────────────
\begin{definition}
[Algorithm]
\label{def: Algorithm}
An algorithm can be viewed as another map $\tilde{f}: X \rightarrow Y$ between the same two spaces. In detail, we should notice that $f$ is a composition of $\fl$ and another function $g$ i.e., $f(x) = g(\fl(x))$. And $f$ maps $X$ to $\fl(Y)$. 
\end{definition}
%────────────────────────────────────────

Hence, $\tilde f$ will be affected by rounding errors. Depending on the circumstances, it may also be affected by all kinds of other complications such as convergence tolerances or even the other jobs running on the computer, in cases where the assignment of computations to processors is not determined until runtime.

\section{Accuracy} 
Except in trivial cases, $\tilde{f}$ cannot be continuous. Nevertheless, a good algorithm should approximate the associated problem $f$. To make this idea quantitative, we may consider the \textbf{absolute error} of a computation, $\|\tilde{f}(x)-f(x)\|$, or the \textbf{relative error},
\begin{equation}
    \label{eq: relative error}
    \frac{\|\tilde{f}(x)-f(x)\|}{\|f(x)\|}
\end{equation}
In this book we mainly utilize relative quantities, and thus (14.1) will be our standard error measure.

If $\tilde{f}$ is a good algorithm, one might naturally expect the relative error to be small, of order $\epsilon_{\text {machine}}$. One might say that an algorithm $\tilde{f}$ for a problem $f$ is \textbf{accurate} if for each $x \in X$,
\begin{align}
    \label{eq: accurate}
\frac{\|\tilde{f}(x)-f(x)\|}{\|f(x)\|}=O\left(\epsilon_{\text {machine}}\right)
\end{align}

\section{Stability} 
If the problem $f$ is ill-conditioned, however, the goal of accuracy as defined by \autoref{eq: accurate} is unreasonably ambitious. Rounding of the input data is unavoidable on a digital computer, and even if all the subsequent computations could be carried out perfectly, this perturbation alone might lead to a significant change in the result. Instead of aiming for accuracy in all cases, the most it is appropriate to aim for in general is stability.


%────────────────────────────────────────
\begin{definition}
[Stability]
\label{def: Stability}
 We say that an algorithm $\tilde{f}$ for a problem $f$ is stable if for each $x \in X$,
\begin{align}
    \label{eq: stab err}
\frac{\|\tilde{f}(x)-f(\tilde{x})\|}{\|f(\tilde{x})\|}=O\left(\epsilon_{\text {machine}}\right),
\end{align}
for some $\tilde{x}$ with
\begin{align}
    \label{eq: stab input}
\frac{\|\tilde{x}-x\|}{\|x\|}=O\left(\epsilon_{\text {machine}}\right).
\end{align}
\end{definition}
%────────────────────────────────────────
In words,
\[
  \text{A stable algorithm gives nearly the right answer to nearly the right question.}  
\]
The motivation for this definition will become clear in the next chapter. We caution the reader that whereas the definitions of stability given here are useful in many parts of numerical linear algebra, the condition $O\left(\epsilon_{\text {machine}}\right)$ is probably too strict to be appropriate for all numerical problems in other areas such as differential equations.

\section{Backward Stability} 
More algorithms of numerical linear algebra satisfy a condition that is both stronger and simpler than stability. 


%────────────────────────────────────────
\begin{definition}
[Backward stable]
\label{def: Backward stable}
We say that an algorithm $\tilde{f}$ for a problem $f$ is backward stable if for each $x \in X$,
\begin{align}
\label{eq: backstab}
\tilde{f}(x)=f(\tilde{x}) \text { for some } \tilde{x} \text { with } \frac{\|\tilde{x}-x\|}{\|x\|}=O\left(\epsilon_{\text {machine}}\right). 
\end{align}
\end{definition}
%────────────────────────────────────────

In words, 
\[
    \text{A backward stable algorithm gives exactly the right answer to nearly the right question.}
\]
Examples are given in the next chapter.   

\section{Independence of Norm}
Our definitions involving $O\left(\epsilon_{\text {machine}}\right)$ have the convenient property that, provided $X$ and $Y$ are finite-dimensional, they are norm-independent. 


%────────────────────────────────────────
\begin{theorem}
\label{thm: indep of norm}
For problems $f$ and algorithms $\tilde{f}$ defined on finite-dimensional spaces $X$ and $Y$, the properties of accuracy, stability, and backward stability all hold or fail to hold independently of the choice of norms in $X$ and $Y$.
\end{theorem}
%────────────────────────────────────────


